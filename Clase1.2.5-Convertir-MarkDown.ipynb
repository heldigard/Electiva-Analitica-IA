{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMSEJjEO3hvKvmhwhLads3X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lqC97hjRQChp","executionInfo":{"status":"ok","timestamp":1755085784567,"user_tz":300,"elapsed":37129,"user":{"displayName":"Eldigardo Camacho","userId":"03066770777404750551"}},"outputId":"2b59c565-e913-4ffc-9b8d-4b71b1bf310e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.11/dist-packages (7.16.6)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (4.13.4)\n","Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert) (6.2.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert) (0.7.1)\n","Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (3.1.6)\n","Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (5.8.1)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert) (0.3.0)\n","Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (3.0.2)\n","Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (3.1.3)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (0.10.2)\n","Requirement already satisfied: nbformat>=5.7 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (5.10.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from nbconvert) (25.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (1.5.1)\n","Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (2.19.2)\n","Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert) (5.7.1)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert) (0.5.1)\n","Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert) (1.4.0)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.7->nbconvert) (4.3.8)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from nbclient>=0.5.0->nbconvert) (6.1.12)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert) (2.21.1)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.7->nbconvert) (4.25.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert) (2.7)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert) (4.14.1)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (2025.4.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.36.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat>=5.7->nbconvert) (0.26.0)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (26.2.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (2.9.0.post0)\n","Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (6.4.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert) (1.17.0)\n","Se encontraron 3 notebooks. Convirtiendo a Markdown...\n","✅ Convertido: Clase2-Electiva-Analitica-IA.ipynb → Clase2-Electiva-Analitica-IA.md\n","✅ Convertido: Clase1-Electiva-Analitica-IA.ipynb → Clase1-Electiva-Analitica-IA.md\n","✅ Convertido: Convertir-MarkDown.ipynb → Convertir-MarkDown.md\n"]}],"source":["# Paso 1: Montar Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Paso 2: Instalar nbconvert (normalmente ya está, pero por si acaso)\n","!pip install nbconvert\n","\n","# Paso 3: Configurar rutas\n","import os\n","import glob\n","import subprocess\n","\n","# Cambia esta ruta a la carpeta donde están tus notebooks\n","notebooks_folder = '/content/drive/MyDrive/Electiva-Analitica-IA'  # ⬅️ CAMBIA ESTO\n","output_folder = os.path.join(notebooks_folder, 'markdown')  # Carpeta para guardar los .md\n","\n","# Crear carpeta de salida si no existe\n","os.makedirs(output_folder, exist_ok=True)\n","\n","# Buscar todos los notebooks en la carpeta\n","notebook_files = glob.glob(os.path.join(notebooks_folder, \"*.ipynb\"))\n","\n","print(f\"Se encontraron {len(notebook_files)} notebooks. Convirtiendo a Markdown...\")\n","\n","# Convertir cada notebook\n","for notebook_path in notebook_files:\n","    filename = os.path.basename(notebook_path)\n","    md_filename = os.path.splitext(filename)[0] + '.md'\n","    output_path = os.path.join(output_folder, md_filename)\n","\n","    # Usar jupyter nbconvert para convertir a markdown\n","    result = subprocess.run([\n","        'jupyter', 'nbconvert',\n","        '--to', 'markdown',\n","        '--output', output_path,\n","        notebook_path\n","    ], capture_output=True, text=True)\n","\n","    if result.returncode == 0:\n","        print(f\"✅ Convertido: {filename} → {md_filename}\")\n","    else:\n","        print(f\"❌ Error al convertir {filename}:\")\n","        print(result.stderr)"]},{"cell_type":"markdown","source":["### **Paso Final (Opcional pero Muy Recomendado): Convirtiendo al Asistente de IA en tu Socio Estratégico**\n","\n","Hemos llegado muy lejos. Hemos preparado los datos, formulado preguntas y creado visualizaciones complejas para responderlas. Hemos actuado como analistas de datos.\n","\n","Ahora, daremos un paso más allá y aprenderemos a usar la IA no solo como un generador de código, sino como un **consultor experto y un socio para la lluvia de ideas**.\n","\n","En este ejercicio, le proporcionaremos a la IA todo el contexto de nuestro trabajo (las Clases 1 y 2) y le pediremos que actúe como un científico de datos senior que revisa nuestro proyecto. Le solicitaremos que nos dé:\n","\n","1.  **Insights directos** sobre los datos que quizás no hemos visto.\n","2.  **Nuevas ideas y caminos** de análisis que podríamos explorar.\n","3.  **Formas alternativas** de escribir nuestro código, usando otras herramientas.\n","4.  **Recomendaciones de buenas prácticas** para mejorar nuestro flujo de trabajo.\n","\n","Este es uno de los usos más poderosos de los LLMs en el análisis de datos: acelerar no solo la escritura de código, sino también la **generación de ideas y la calidad del análisis**.\n","\n","**Instrucción:** Abre un nuevo chat con tu asistente de IA. Primero, copia y pega el contenido completo de los archivos `Clase1-Electiva-Analitica-IA.md` y `Clase2-Electiva-Analitica-IA.md` para darle todo el contexto. Inmediatamente después, sin añadir más texto, copia y pega el siguiente \"Prompt Maestro\"."],"metadata":{"id":"Tki-KC7aUA1o"}},{"cell_type":"markdown","source":["### **Prompt Maestro (Para copiar en el nuevo chat después de los archivos markdown)**\n","\n","> Actúa como un científico de datos senior y consultor experto. Acabas de revisar los dos notebooks (Clase 1 y Clase 2) que te he proporcionado, los cuales detallan un análisis exploratorio de datos sobre siniestros viales en Bogotá. Basándote en todo ese contexto, por favor, dame una revisión completa de este proyecto estructurada en los siguientes cuatro puntos:\n",">\n","> **1. Generación de Insights Directos:** Basado en los gráficos y tablas del análisis, ¿qué 3 a 5 conclusiones o insights clave puedes extraer? Resume los hallazgos más importantes como si los estuvieras presentando a un cliente.\n",">\n","> **2. Brainstorming y Rutas de Análisis Alternativas:** Nuestro análisis se centró en las hojas `SINIESTROS` y `ACTOR_VIAL`. Viendo el panorama completo (incluyendo las hojas `VEHICULOS` e `HIPOTESIS`), ¿qué nuevas preguntas de negocio podríamos responder? Sugiere al menos tres nuevas rutas de investigación que podrían generar valor.\n",">\n","> **3. Alternativas de Código y Bibliotecas:** Los gráficos se hicieron principalmente con `seaborn`. Para fines de aprendizaje, muéstrame cómo se podría haber creado uno de los gráficos simples, como el de \"Distribución de Siniestros por Gravedad\" (Paso 2, Clase 2), utilizando únicamente la biblioteca `matplotlib` (el \"backend\" de seaborn). Explica brevemente la diferencia en el enfoque.\n",">\n","> **4. Recomendaciones de Buenas Prácticas:** Revisando el flujo de trabajo general de los notebooks, ¿qué recomendaciones de buenas prácticas de programación y análisis de datos podrías dar para hacer el proyecto más robusto, eficiente y mantenible a futuro?"],"metadata":{"id":"zH_HjK42UU3p"}},{"cell_type":"markdown","source":["### **Ejemplo de una Respuesta Ideal del Asistente de IA**"],"metadata":{"id":"b35yVK8cUj3P"}},{"cell_type":"markdown","source":["¡Excelente trabajo en este análisis! He revisado a fondo los dos notebooks y el proyecto tiene una base muy sólida. Aquí tienes mi consultoría basada en los cuatro puntos que solicitaste:\n","\n","#### **1. Insights Directos del Análisis**\n","\n","Si tuviera que presentar los hallazgos clave a un cliente o a la alcaldía, me centraría en estos puntos:\n","\n","*   **El Riesgo tiene Hora y Día:** La siniestralidad no es aleatoria. Se concentra masivamente en las horas pico de tráfico (7-8 a.m. y 5-7 p.m.), con un pico máximo sorprendente al mediodía (1-2 p.m.). Los viernes y sábados son, por mucho, los días más peligrosos.\n","*   **La Paradoja de la Gravedad:** Aunque la mayoría de los incidentes son solo daños materiales, esto no debe generar complacencia. Cuando ocurren fatalidades, el perfil de la víctima cambia drásticamente.\n","*   **Vulnerabilidad Extrema de Motociclistas y Peatones:** Este es el insight más crítico. En accidentes mortales, estos dos grupos constituyen la gran mayoría de las víctimas, muy por encima de los conductores de automóviles.\n","*   **Disparidad de Género en Fatalidades:** El análisis final revela un dato contundente: la inmensa mayoría de las víctimas mortales en todas las categorías de actores viales son hombres. Esto sugiere que los comportamientos de riesgo pueden tener un fuerte componente de género.\n","\n","#### **2. Brainstorming y Rutas de Análisis Alternativas**\n","\n","El análisis actual es excelente, pero podríamos profundizar mucho más utilizando los datos que aún no hemos tocado:\n","\n","*   **Análisis Causa-Efecto (usando la hoja `HIPOTESIS`):** Podríamos responder: **\"¿Cuál es la causa más común (ej. exceso de velocidad, no respetar señales) para los siniestros que involucran motociclistas?\"**. Unir `df_completo` con la hoja `HIPOTESIS` nos permitiría pasar del \"qué\" al \"**porqué**\" de los accidentes.\n","*   **Análisis por Tipo de Vehículo (usando la hoja `VEHICULOS`):** Podríamos investigar: **\"¿Los vehículos de servicio público están más involucrados en siniestros con heridos que los vehículos particulares?\"**. Esto ayudaría a enfocar políticas de regulación y formación específicas para el transporte público o de carga.\n","*   **Análisis Geoespacial (usando la columna `DIRECCION`):** En la Clase 1 eliminamos la columna `DIRECCION` por su alta cardinalidad. ¡Pero podríamos recuperarla! Usando librerías como `geopandas` y `folium`, podríamos convertir las direcciones en coordenadas y crear un **mapa de calor** de Bogotá para visualizar los \"puntos calientes\" donde se concentran los accidentes mortales. Esto sería visualmente muy impactante y útil para la planificación urbana.\n","\n","#### **3. Alternativas de Código: Matplotlib vs. Seaborn**\n","\n","¡Claro! Seaborn es fantástica porque con una línea hace mucho (`countplot`). Matplotlib te da un control más granular, pero requiere más pasos. Así se vería el gráfico de \"Distribución de Siniestros por Gravedad\" solo con Matplotlib:\n","\n","```python\n","# Preparación de los datos (la misma que para seaborn)\n","gravedad_counts = df_siniestros['GRAVEDAD'].value_counts()\n","\n","# -- Código usando solo Matplotlib --\n","# 1. Crear la figura y los ejes\n","fig, ax = plt.subplots(figsize=(10, 6))\n","\n","# 2. Crear el gráfico de barras explícitamente\n","ax.bar(x=gravedad_counts.index, height=gravedad_counts.values, color='steelblue')\n","\n","# 3. Añadir títulos y etiquetas (muy similar)\n","ax.set_title('Distribución de Siniestros por Gravedad en Bogotá (Matplotlib)', fontsize=16)\n","ax.set_xlabel('Gravedad del Siniestro', fontsize=12)\n","ax.set_ylabel('Cantidad de Siniestros', fontsize=12)\n","\n","# 4. Añadir una grilla para mejor lectura\n","ax.grid(axis='y', linestyle='--', alpha=0.7)\n","\n","# 5. Mostrar el gráfico\n","plt.show()\n","```\n","**Diferencia de enfoque:** Con `seaborn`, le pasas el DataFrame y le dices \"cuenta los valores en esta columna\". Con `matplotlib`, tú primero debes calcular los valores (con `.value_counts()`) y luego le dices \"dibuja estas barras con estas etiquetas y esta altura\". Matplotlib es más explícito y personalizable, Seaborn es más rápido para gráficos estándar.\n","\n","#### **4. Recomendaciones de Buenas Prácticas**\n","\n","El flujo es muy bueno para un entorno educativo. Para llevarlo a un nivel de producción, recomendaría:\n","\n","*   **Modularizar el Código con Funciones:** En lugar de repetir la lógica de mapeo para cada columna (`GRAVEDAD`, `CLASE`, etc.), se podría crear una única función `mapear_columna(df, nombre_columna, df_diccionario)`. Esto hace el código más limpio, reutilizable y fácil de depurar (DRY - Don't Repeat Yourself).\n","*   **Manejo de Errores Centralizado:** El código final que recarga los datos es una excelente práctica. En un proyecto más grande, esto iría en un script de \"preparación de datos\" que se ejecuta primero, y los análisis posteriores cargarían el dataset ya limpio y fusionado.\n","*   **Uso de Archivos de Configuración:** En lugar de tener la ruta a Google Drive escrita directamente en el código (`hardcodeada`), en un proyecto grande se usaría un archivo de configuración (ej. `config.yaml`) donde se guardan rutas y otros parámetros, haciendo el código más portable.\n","*   **Documentación (Docstrings):** A medida que se crean funciones, es una buena práctica añadir \"docstrings\" que expliquen qué hace la función, qué argumentos recibe y qué devuelve. Esto es invaluable para el trabajo en equipo y para tu \"yo\" del futuro.\n","\n","¡Espero que esta revisión sea de gran ayuda! El proyecto tiene un potencial enorme y sigue una ruta lógica y muy profesional."],"metadata":{"id":"tTjuecxgUsd3"}}]}